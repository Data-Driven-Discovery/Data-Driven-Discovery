<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Classification Algorithms Every Data Scientist Should Know | Data Driven Discovery - D3</title>
<meta name="keywords" content="Supervised Learning, Data Science, Machine Learning, Tutorial">
<meta name="description" content="Classification Algorithms Every Data Scientist Should Know Classification algorithms are indeed the backbone of machine learning. They help in predicting the category or class of certain data points based on past observations. The reliability of their prediction is staggeringly good, making them widely used across several domains. This post will walk you through some pivotal classification algorithms every data scientist should know.
Introduction Before we begin, let&rsquo;s get a sense of what we are dealing with.">
<meta name="author" content="">
<link rel="canonical" href="https://lustrous-paprenjak-b7c3d8.netlify.app/basics/Classification_Algorithms_every_Data_Scientist_should_know/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/apple-touch-icon.png">
<link rel="mask-icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Classification Algorithms Every Data Scientist Should Know" />
<meta property="og:description" content="Classification Algorithms Every Data Scientist Should Know Classification algorithms are indeed the backbone of machine learning. They help in predicting the category or class of certain data points based on past observations. The reliability of their prediction is staggeringly good, making them widely used across several domains. This post will walk you through some pivotal classification algorithms every data scientist should know.
Introduction Before we begin, let&rsquo;s get a sense of what we are dealing with." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lustrous-paprenjak-b7c3d8.netlify.app/basics/Classification_Algorithms_every_Data_Scientist_should_know/" /><meta property="article:section" content="basics" />
<meta property="article:published_time" content="2024-02-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-02-05T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Classification Algorithms Every Data Scientist Should Know"/>
<meta name="twitter:description" content="Classification Algorithms Every Data Scientist Should Know Classification algorithms are indeed the backbone of machine learning. They help in predicting the category or class of certain data points based on past observations. The reliability of their prediction is staggeringly good, making them widely used across several domains. This post will walk you through some pivotal classification algorithms every data scientist should know.
Introduction Before we begin, let&rsquo;s get a sense of what we are dealing with."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Basics",
      "item": "https://lustrous-paprenjak-b7c3d8.netlify.app/basics/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Classification Algorithms Every Data Scientist Should Know",
      "item": "https://lustrous-paprenjak-b7c3d8.netlify.app/basics/Classification_Algorithms_every_Data_Scientist_should_know/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Classification Algorithms Every Data Scientist Should Know",
  "name": "Classification Algorithms Every Data Scientist Should Know",
  "description": "Classification Algorithms Every Data Scientist Should Know Classification algorithms are indeed the backbone of machine learning. They help in predicting the category or class of certain data points based on past observations. The reliability of their prediction is staggeringly good, making them widely used across several domains. This post will walk you through some pivotal classification algorithms every data scientist should know.\nIntroduction Before we begin, let\u0026rsquo;s get a sense of what we are dealing with.",
  "keywords": [
    "Supervised Learning", "Data Science", "Machine Learning", "Tutorial"
  ],
  "articleBody": "Classification Algorithms Every Data Scientist Should Know Classification algorithms are indeed the backbone of machine learning. They help in predicting the category or class of certain data points based on past observations. The reliability of their prediction is staggeringly good, making them widely used across several domains. This post will walk you through some pivotal classification algorithms every data scientist should know.\nIntroduction Before we begin, let’s get a sense of what we are dealing with. By definition, classification is a two-step process consisting of learning step and prediction step. In the learning step, the model learns from the training dataset, and in the prediction step, it makes predictions on the input data. Some popular use cases of classification include email spam detection, bank customer churn prediction, tumor detection, etc.\nHere, we will discuss five commonly used classification algorithms in the data science realm:\nLogistic Regression Decision Trees Random Forests Support Vector Machines (SVM) K-Nearest Neighbors (KNN) We’ll show small examples using scikit-learn, one of the most popular machine learning libraries in Python.\n1. Logistic Regression Despite its name, Logistic Regression (LR) is a fundamental classification method. It’s simple and does not require high computational power as compared to complex models like SVM and Neural Networks.\nEssentially, LR computes the weights of the variables that maximize the likelihood of predicting correct class probabilities when the dependent variable is binary.\nfrom sklearn.linear_model import LogisticRegression from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split iris = load_iris() X = iris.data y = iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) lr = LogisticRegression(max_iter=1000) lr.fit(X_train, y_train) lr.score(X_test, y_test) The output score is a measure of accuracy on the test set. It lies between 0 and 1, with 1 indicating the best performance.\n2. Decision Trees Decision Trees are simple yet powerful algorithms used for both classification and regression problems. As the name suggests, a decision tree uses a tree-like model of decisions where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and the leaf nodes represent classes or class distributions.\nfrom sklearn.tree import DecisionTreeClassifier dt = DecisionTreeClassifier() dt.fit(X_train, y_train) dt.score(X_test, y_test) 3. Random Forests While Decision Trees are simple and easy to implement, they suffer from instability as small changes can lead to a completely different tree. This is where Random Forests step in. Random Forests mitigate this problem by combining the results of multiple decision trees built on different samples of the dataset.\nfrom sklearn.ensemble import RandomForestClassifier rf = RandomForestClassifier(n_estimators=100) rf.fit(X_train, y_train) rf.score(X_test, y_test) 4. Support Vector Machines (SVM) SVM is a powerful, flexible but computationally expensive classification algorithm that can also handle continuous and categorical variables. SVM constructs hyperplanes in multidimensional space to separate different classes.\nfrom sklearn import svm svc = svm.SVC() svc.fit(X_train, y_train) svc.score(X_test, y_test) 5. K-Nearest Neighbors (KNN) KNN is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems. It classifies new cases based on a similarity measure (e.g. distance functions).\nfrom sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier(n_neighbors=5) knn.fit(X_train, y_train) knn.score(X_test, y_test) Conclusion The five classification algorithms discussed in this post are foundational knowledge for every data scientist. They come with their merits and demerits, and their selection depends primarily on the problem at hand. For more structured data, Decision Trees, Random Forests, and Logistic Regression can be good starting points. For less structured data, more complex models like SVM or Neural Networks can be considered. As always in machine learning and data science, the golden rule is: there’s no free lunch. Each algorithm shines in certain domains and conditions, so it requires experience and continuous learning to select the right algorithm for specific tasks.\n",
  "wordCount" : "616",
  "inLanguage": "en",
  "datePublished": "2024-02-05T00:00:00Z",
  "dateModified": "2024-02-05T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lustrous-paprenjak-b7c3d8.netlify.app/basics/Classification_Algorithms_every_Data_Scientist_should_know/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Driven Discovery - D3",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lustrous-paprenjak-b7c3d8.netlify.app/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lustrous-paprenjak-b7c3d8.netlify.app/" accesskey="h" title="Data Driven Discovery - D3 (Alt + H)">Data Driven Discovery - D3</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Classification Algorithms Every Data Scientist Should Know
    </h1>
    <div class="post-meta"><span title='2024-02-05 00:00:00 +0000 UTC'>February 5, 2024</span>

</div>
  </header> 
  <div class="post-content"><h1 id="classification-algorithms-every-data-scientist-should-know">Classification Algorithms Every Data Scientist Should Know<a hidden class="anchor" aria-hidden="true" href="#classification-algorithms-every-data-scientist-should-know">#</a></h1>
<p>Classification algorithms are indeed the backbone of machine learning. They help in predicting the category or class of certain data points based on past observations. The reliability of their prediction is staggeringly good, making them widely used across several domains. This post will walk you through some pivotal classification algorithms every data scientist should know.</p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Before we begin, let&rsquo;s get a sense of what we are dealing with. By definition, classification is a two-step process consisting of learning step and prediction step. In the learning step, the model learns from the training dataset, and in the prediction step, it makes predictions on the input data. Some popular use cases of classification include email spam detection, bank customer churn prediction, tumor detection, etc.</p>
<p>Here, we will discuss five commonly used classification algorithms in the data science realm:</p>
<ul>
<li>Logistic Regression</li>
<li>Decision Trees</li>
<li>Random Forests</li>
<li>Support Vector Machines (SVM)</li>
<li>K-Nearest Neighbors (KNN)</li>
</ul>
<p>We&rsquo;ll show small examples using <code>scikit-learn</code>, one of the most popular machine learning libraries in Python.</p>
<h2 id="1-logistic-regression">1. Logistic Regression<a hidden class="anchor" aria-hidden="true" href="#1-logistic-regression">#</a></h2>
<p>Despite its name, Logistic Regression (LR) is a fundamental classification method. It&rsquo;s simple and does not require high computational power as compared to complex models like SVM and Neural Networks.</p>
<p>Essentially, LR computes the weights of the variables that maximize the likelihood of predicting correct class probabilities when the dependent variable is binary.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> load_iris
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>iris <span style="color:#f92672">=</span> load_iris()
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>target
</span></span><span style="display:flex;"><span>X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>lr <span style="color:#f92672">=</span> LogisticRegression(max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>lr<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>lr<span style="color:#f92672">.</span>score(X_test, y_test)
</span></span></code></pre></div><p>The output score is a measure of accuracy on the test set. It lies between 0 and 1, with 1 indicating the best performance.</p>
<h2 id="2-decision-trees">2. Decision Trees<a hidden class="anchor" aria-hidden="true" href="#2-decision-trees">#</a></h2>
<p>Decision Trees are simple yet powerful algorithms used for both classification and regression problems. As the name suggests, a decision tree uses a tree-like model of decisions where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and the leaf nodes represent classes or class distributions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.tree <span style="color:#f92672">import</span> DecisionTreeClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dt <span style="color:#f92672">=</span> DecisionTreeClassifier()
</span></span><span style="display:flex;"><span>dt<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>dt<span style="color:#f92672">.</span>score(X_test, y_test)
</span></span></code></pre></div><h2 id="3-random-forests">3. Random Forests<a hidden class="anchor" aria-hidden="true" href="#3-random-forests">#</a></h2>
<p>While Decision Trees are simple and easy to implement, they suffer from instability as small changes can lead to a completely different tree. This is where Random Forests step in. Random Forests mitigate this problem by combining the results of multiple decision trees built on different samples of the dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rf <span style="color:#f92672">=</span> RandomForestClassifier(n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>rf<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>rf<span style="color:#f92672">.</span>score(X_test, y_test)
</span></span></code></pre></div><h2 id="4-support-vector-machines-svm">4. Support Vector Machines (SVM)<a hidden class="anchor" aria-hidden="true" href="#4-support-vector-machines-svm">#</a></h2>
<p>SVM is a powerful, flexible but computationally expensive classification algorithm that can also handle continuous and categorical variables. SVM constructs hyperplanes in multidimensional space to separate different classes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> svm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>svc <span style="color:#f92672">=</span> svm<span style="color:#f92672">.</span>SVC()
</span></span><span style="display:flex;"><span>svc<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>svc<span style="color:#f92672">.</span>score(X_test, y_test)
</span></span></code></pre></div><h2 id="5-k-nearest-neighbors-knn">5. K-Nearest Neighbors (KNN)<a hidden class="anchor" aria-hidden="true" href="#5-k-nearest-neighbors-knn">#</a></h2>
<p>KNN is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems. It classifies new cases based on a similarity measure (e.g. distance functions).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.neighbors <span style="color:#f92672">import</span> KNeighborsClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>knn <span style="color:#f92672">=</span> KNeighborsClassifier(n_neighbors<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>knn<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>knn<span style="color:#f92672">.</span>score(X_test, y_test)
</span></span></code></pre></div><h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>The five classification algorithms discussed in this post are foundational knowledge for every data scientist. They come with their merits and demerits, and their selection depends primarily on the problem at hand. For more structured data, Decision Trees, Random Forests, and Logistic Regression can be good starting points. For less structured data, more complex models like SVM or Neural Networks can be considered. As always in machine learning and data science, the golden rule is: there&rsquo;s no free lunch. Each algorithm shines in certain domains and conditions, so it requires experience and continuous learning to select the right algorithm for specific tasks.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Supervised-Learning/">Supervised Learning</a></li>
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Data-Science/">Data Science</a></li>
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Machine-Learning/">Machine Learning</a></li>
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Tutorial/">Tutorial</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://lustrous-paprenjak-b7c3d8.netlify.app/">Data Driven Discovery - D3</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
