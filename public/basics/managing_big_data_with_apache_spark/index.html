<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Managing Big Data with Apache Spark | Data Driven Discovery - D3</title>
<meta name="keywords" content="Big Data, Apache Spark, Data Engineering">
<meta name="description" content="Managing Big Data with Apache Spark In this digital age, virtually every aspect of our lives generates data. From our social media activities to our online shopping habits, data is being harvested and used in ways that we could hardly have imagined even a decade ago. Among the tools designed to handle big data analytics, Apache Spark stands out due to its speed, ease of use, and general-purpose processing power.">
<meta name="author" content="">
<link rel="canonical" href="https://lustrous-paprenjak-b7c3d8.netlify.app/basics/Managing_Big_Data_with_Apache_Spark/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/apple-touch-icon.png">
<link rel="mask-icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Managing Big Data with Apache Spark" />
<meta property="og:description" content="Managing Big Data with Apache Spark In this digital age, virtually every aspect of our lives generates data. From our social media activities to our online shopping habits, data is being harvested and used in ways that we could hardly have imagined even a decade ago. Among the tools designed to handle big data analytics, Apache Spark stands out due to its speed, ease of use, and general-purpose processing power." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lustrous-paprenjak-b7c3d8.netlify.app/basics/Managing_Big_Data_with_Apache_Spark/" /><meta property="article:section" content="basics" />
<meta property="article:published_time" content="2024-02-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-02-05T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Managing Big Data with Apache Spark"/>
<meta name="twitter:description" content="Managing Big Data with Apache Spark In this digital age, virtually every aspect of our lives generates data. From our social media activities to our online shopping habits, data is being harvested and used in ways that we could hardly have imagined even a decade ago. Among the tools designed to handle big data analytics, Apache Spark stands out due to its speed, ease of use, and general-purpose processing power."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Basics",
      "item": "https://lustrous-paprenjak-b7c3d8.netlify.app/basics/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Managing Big Data with Apache Spark",
      "item": "https://lustrous-paprenjak-b7c3d8.netlify.app/basics/Managing_Big_Data_with_Apache_Spark/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Managing Big Data with Apache Spark",
  "name": "Managing Big Data with Apache Spark",
  "description": "Managing Big Data with Apache Spark In this digital age, virtually every aspect of our lives generates data. From our social media activities to our online shopping habits, data is being harvested and used in ways that we could hardly have imagined even a decade ago. Among the tools designed to handle big data analytics, Apache Spark stands out due to its speed, ease of use, and general-purpose processing power.",
  "keywords": [
    "Big Data", "Apache Spark", "Data Engineering"
  ],
  "articleBody": "Managing Big Data with Apache Spark In this digital age, virtually every aspect of our lives generates data. From our social media activities to our online shopping habits, data is being harvested and used in ways that we could hardly have imagined even a decade ago. Among the tools designed to handle big data analytics, Apache Spark stands out due to its speed, ease of use, and general-purpose processing power.\nIntroduction Apache Spark is an open-source, distributed computing system used for big data processing and analytics. Thanks in part to its in-memory data processing capabilities, it has the ability to handle large-scale data efficiently. It allows developers to perform complex operations on large volumes of data across a distributed environment, whether that environment is in the cloud or on-premises.\nIn this article, we’re going to talk about how to manage big data with Apache Spark. We’ll delve into some code examples that demonstrate how to do data transformations, run SQL queries, and build machine learning models, all with Spark.\nMain Body Installing PySpark PySpark, the Python library for Spark, allows you to interface with Spark’s functionalities using Python. Before we get started, let’s install PySpark. You can do this with pip:\npip install pyspark Starting a SparkSession We’ll start by creating a SparkSession, which is the entry point to any Spark functionality.\nfrom pyspark.sql import SparkSession # start Spark session spark = SparkSession.builder.master(\"local\").appName(\"BigData\").getOrCreate() Data Transformation Suppose we have a dataset data\ndata = [('James','','Smith','1991-04-01','M',3000), ('Michael','Rose','','2000-05-19','M',4000), ('Robert','','Williams','1978-09-05','M',4000), ('Maria','Anne','Jones','1967-12-01','F',4000), ('Jen','Mary','Brown','1980-02-17','F',-1) ] columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"] # create pandas dataframe df = spark.createDataFrame(data=data, schema = columns) [INSERT IMAGE HERE] ![alt text](./image.png) Now that we have our dataframe, we can perform a simple transformation: select a couple of columns and calculate their average.\nfrom pyspark.sql import functions as F # calculate average salary df_agg = df.agg(F.avg('salary').alias('average_salary')) # show the result df_agg.show() # output: # +--------------+ # |average_salary| # +--------------+ # | 3000.0| # +--------------+ Running SQL Queries Spark SQL supports a variety of structured data sources, including Hive, Avro, Parquet, ORC, JSON, and JDBC.\n# register the DataFrame as a SQL temporary view df.createOrReplaceTempView(\"people\") # run an SQL query sql_query = \"SELECT gender, count(*) as count FROM people GROUP BY gender\" sql_results = spark.sql(sql_query) # show the results sql_results.show() # output: # +------+-----+ # |gender|count| # +------+-----+ # | F| 2| # | M| 3| # +------+-----+ Machine Learning with Spark In addition to managing big data processing, Spark also has integrated machine learning libraries. To illustrate, let’s start with a hypothetical DataFrame and run a simple linear regression model.\nfrom pyspark.ml.regression import LinearRegression # a hypothetical DataFrame, df_ml, with two columns: Features and Label # define the model lr = LinearRegression(featuresCol='Features', labelCol='Label') # fit the model lr_model = lr.fit(df_ml) # evaluate the model evaluation_summary = lr_model.evaluate(df_ml) print(\"Coefficients: \" + str(lr_model.coefficients)) print(\"RMSE: %f\" % evaluation_summary.rootMeanSquaredError) # output might look something like the following, depending of your input data: # Coefficients: [3.287, -9.283, 5.154, ...] # RMSE: 0.876543 Conclusion Apache Spark provides one of the most robust platforms for big data processing and analytics. It allows not only for efficient data transformations but also offers a host of machine learning libraries and the ability to run SQL queries on big data. Understanding how to use Spark’s wide range of capabilities is a necessary skill for any modern data professional. While we’ve only scratched the surface in this tutorial, we hope it serves as a starting point for your exploration with Apache Spark.\nWhether you’re a data scientist needing to handle large datasets, a data engineer designing big data pipelines, or an ML engineer working on training complex models, Spark offers tools and functions that can streamline and optimize your work.\n",
  "wordCount" : "614",
  "inLanguage": "en",
  "datePublished": "2024-02-05T00:00:00Z",
  "dateModified": "2024-02-05T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lustrous-paprenjak-b7c3d8.netlify.app/basics/Managing_Big_Data_with_Apache_Spark/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Driven Discovery - D3",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lustrous-paprenjak-b7c3d8.netlify.app/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lustrous-paprenjak-b7c3d8.netlify.app/" accesskey="h" title="Data Driven Discovery - D3 (Alt + H)">Data Driven Discovery - D3</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Managing Big Data with Apache Spark
    </h1>
    <div class="post-meta"><span title='2024-02-05 00:00:00 +0000 UTC'>February 5, 2024</span>

</div>
  </header> 
  <div class="post-content"><h1 id="managing-big-data-with-apache-spark">Managing Big Data with Apache Spark<a hidden class="anchor" aria-hidden="true" href="#managing-big-data-with-apache-spark">#</a></h1>
<p>In this digital age, virtually every aspect of our lives generates data. From our social media activities to our online shopping habits, data is being harvested and used in ways that we could hardly have imagined even a decade ago. Among the tools designed to handle big data analytics, Apache Spark stands out due to its speed, ease of use, and general-purpose processing power.</p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Apache Spark is an open-source, distributed computing system used for big data processing and analytics. Thanks in part to its in-memory data processing capabilities, it has the ability to handle large-scale data efficiently. It allows developers to perform complex operations on large volumes of data across a distributed environment, whether that environment is in the cloud or on-premises.</p>
<p>In this article, we&rsquo;re going to talk about how to manage big data with Apache Spark. We&rsquo;ll delve into some code examples that demonstrate how to do data transformations, run SQL queries, and build machine learning models, all with Spark.</p>
<h2 id="main-body">Main Body<a hidden class="anchor" aria-hidden="true" href="#main-body">#</a></h2>
<h3 id="installing-pyspark">Installing PySpark<a hidden class="anchor" aria-hidden="true" href="#installing-pyspark">#</a></h3>
<p>PySpark, the Python library for Spark, allows you to interface with Spark’s functionalities using Python. Before we get started, let&rsquo;s install PySpark. You can do this with pip:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install pyspark
</span></span></code></pre></div><h3 id="starting-a-sparksession">Starting a SparkSession<a hidden class="anchor" aria-hidden="true" href="#starting-a-sparksession">#</a></h3>
<p>We’ll start by creating a <code>SparkSession</code>, which is the entry point to any Spark functionality.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.sql <span style="color:#f92672">import</span> SparkSession
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># start Spark session</span>
</span></span><span style="display:flex;"><span>spark <span style="color:#f92672">=</span> SparkSession<span style="color:#f92672">.</span>builder<span style="color:#f92672">.</span>master(<span style="color:#e6db74">&#34;local&#34;</span>)<span style="color:#f92672">.</span>appName(<span style="color:#e6db74">&#34;BigData&#34;</span>)<span style="color:#f92672">.</span>getOrCreate()
</span></span></code></pre></div><h3 id="data-transformation">Data Transformation<a hidden class="anchor" aria-hidden="true" href="#data-transformation">#</a></h3>
<p>Suppose we have a dataset <code>data</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>data <span style="color:#f92672">=</span> [(<span style="color:#e6db74">&#39;James&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>,<span style="color:#e6db74">&#39;Smith&#39;</span>,<span style="color:#e6db74">&#39;1991-04-01&#39;</span>,<span style="color:#e6db74">&#39;M&#39;</span>,<span style="color:#ae81ff">3000</span>),
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#39;Michael&#39;</span>,<span style="color:#e6db74">&#39;Rose&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>,<span style="color:#e6db74">&#39;2000-05-19&#39;</span>,<span style="color:#e6db74">&#39;M&#39;</span>,<span style="color:#ae81ff">4000</span>),
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#39;Robert&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>,<span style="color:#e6db74">&#39;Williams&#39;</span>,<span style="color:#e6db74">&#39;1978-09-05&#39;</span>,<span style="color:#e6db74">&#39;M&#39;</span>,<span style="color:#ae81ff">4000</span>),
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#39;Maria&#39;</span>,<span style="color:#e6db74">&#39;Anne&#39;</span>,<span style="color:#e6db74">&#39;Jones&#39;</span>,<span style="color:#e6db74">&#39;1967-12-01&#39;</span>,<span style="color:#e6db74">&#39;F&#39;</span>,<span style="color:#ae81ff">4000</span>),
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#39;Jen&#39;</span>,<span style="color:#e6db74">&#39;Mary&#39;</span>,<span style="color:#e6db74">&#39;Brown&#39;</span>,<span style="color:#e6db74">&#39;1980-02-17&#39;</span>,<span style="color:#e6db74">&#39;F&#39;</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;firstname&#34;</span>,<span style="color:#e6db74">&#34;middlename&#34;</span>,<span style="color:#e6db74">&#34;lastname&#34;</span>,<span style="color:#e6db74">&#34;dob&#34;</span>,<span style="color:#e6db74">&#34;gender&#34;</span>,<span style="color:#e6db74">&#34;salary&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create pandas dataframe</span>
</span></span><span style="display:flex;"><span>df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>createDataFrame(data<span style="color:#f92672">=</span>data, schema <span style="color:#f92672">=</span> columns)
</span></span></code></pre></div><h4 id="insert-image-here">[INSERT IMAGE HERE]<a hidden class="anchor" aria-hidden="true" href="#insert-image-here">#</a></h4>
<pre><code>![alt text](./image.png)
</code></pre>
<p><strong>Now that we have our dataframe, we can perform a simple transformation: select a couple of columns and calculate their average.</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.sql <span style="color:#f92672">import</span> functions <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># calculate average salary</span>
</span></span><span style="display:flex;"><span>df_agg <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>agg(F<span style="color:#f92672">.</span>avg(<span style="color:#e6db74">&#39;salary&#39;</span>)<span style="color:#f92672">.</span>alias(<span style="color:#e6db74">&#39;average_salary&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># show the result</span>
</span></span><span style="display:flex;"><span>df_agg<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># output:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># +--------------+</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># |average_salary|</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># +--------------+</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># |        3000.0|</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># +--------------+</span>
</span></span></code></pre></div><h3 id="running-sql-queries">Running SQL Queries<a hidden class="anchor" aria-hidden="true" href="#running-sql-queries">#</a></h3>
<p>Spark SQL supports a variety of structured data sources, including Hive, Avro, Parquet, ORC, JSON, and JDBC.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># register the DataFrame as a SQL temporary view</span>
</span></span><span style="display:flex;"><span>df<span style="color:#f92672">.</span>createOrReplaceTempView(<span style="color:#e6db74">&#34;people&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># run an SQL query</span>
</span></span><span style="display:flex;"><span>sql_query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;SELECT gender, count(*) as count FROM people GROUP BY gender&#34;</span>
</span></span><span style="display:flex;"><span>sql_results <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>sql(sql_query)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># show the results</span>
</span></span><span style="display:flex;"><span>sql_results<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># output:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># +------+-----+</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># |gender|count|</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># +------+-----+</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># |     F|    2|</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># |     M|    3|</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># +------+-----+</span>
</span></span></code></pre></div><h3 id="machine-learning-with-spark">Machine Learning with Spark<a hidden class="anchor" aria-hidden="true" href="#machine-learning-with-spark">#</a></h3>
<p>In addition to managing big data processing, Spark also has integrated machine learning libraries. To illustrate, let&rsquo;s start with a hypothetical DataFrame and run a simple linear regression model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.ml.regression <span style="color:#f92672">import</span> LinearRegression
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># a hypothetical DataFrame, df_ml, with two columns: Features and Label</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># define the model</span>
</span></span><span style="display:flex;"><span>lr <span style="color:#f92672">=</span> LinearRegression(featuresCol<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Features&#39;</span>, labelCol<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Label&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># fit the model</span>
</span></span><span style="display:flex;"><span>lr_model <span style="color:#f92672">=</span> lr<span style="color:#f92672">.</span>fit(df_ml)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># evaluate the model</span>
</span></span><span style="display:flex;"><span>evaluation_summary <span style="color:#f92672">=</span> lr_model<span style="color:#f92672">.</span>evaluate(df_ml)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Coefficients: &#34;</span> <span style="color:#f92672">+</span> str(lr_model<span style="color:#f92672">.</span>coefficients))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;RMSE: </span><span style="color:#e6db74">%f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> evaluation_summary<span style="color:#f92672">.</span>rootMeanSquaredError)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># output might look something like the following, depending of your input data:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Coefficients: [3.287, -9.283, 5.154, ...]</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># RMSE: 0.876543</span>
</span></span></code></pre></div><h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>Apache Spark provides one of the most robust platforms for big data processing and analytics. It allows not only for efficient data transformations but also offers a host of machine learning libraries and the ability to run SQL queries on big data. Understanding how to use Spark&rsquo;s wide range of capabilities is a necessary skill for any modern data professional. While we&rsquo;ve only scratched the surface in this tutorial, we hope it serves as a starting point for your exploration with Apache Spark.</p>
<p>Whether you&rsquo;re a data scientist needing to handle large datasets, a data engineer designing big data pipelines, or an ML engineer working on training complex models, Spark offers tools and functions that can streamline and optimize your work.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Big-Data/">Big Data</a></li>
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Apache-Spark/">Apache Spark</a></li>
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Data-Engineering/">Data Engineering</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://lustrous-paprenjak-b7c3d8.netlify.app/">Data Driven Discovery - D3</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
