<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Data Driven Discovery - D3</title>
<meta name="keywords" content="">
<meta name="description" content="Advanced Natural Language Processing: Techniques for Semantic Analysis and Generation In the fast-evolving field of Natural Language Processing (NLP), understanding the nuances of language, its structure, and meaning has never been more important. Advancements in machine learning, data science, and artificial intelligence have significantly improved our ability to analyze and generate human language computationally. This article delves into advanced techniques for semantic analysis and generation, offering insights and practical examples for both beginners and seasoned practitioners in the domains of Data Science, Machine Learning, and NLP.">
<meta name="author" content="">
<link rel="canonical" href="http://example.org/advanced/Advanced_Natural_Language_Processing_Techniques_for_Semantic_Analysis_and_Generation/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://example.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://example.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://example.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://example.org/apple-touch-icon.png">
<link rel="mask-icon" href="http://example.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="" />
<meta property="og:description" content="Advanced Natural Language Processing: Techniques for Semantic Analysis and Generation In the fast-evolving field of Natural Language Processing (NLP), understanding the nuances of language, its structure, and meaning has never been more important. Advancements in machine learning, data science, and artificial intelligence have significantly improved our ability to analyze and generate human language computationally. This article delves into advanced techniques for semantic analysis and generation, offering insights and practical examples for both beginners and seasoned practitioners in the domains of Data Science, Machine Learning, and NLP." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/advanced/Advanced_Natural_Language_Processing_Techniques_for_Semantic_Analysis_and_Generation/" /><meta property="article:section" content="advanced" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="Advanced Natural Language Processing: Techniques for Semantic Analysis and Generation In the fast-evolving field of Natural Language Processing (NLP), understanding the nuances of language, its structure, and meaning has never been more important. Advancements in machine learning, data science, and artificial intelligence have significantly improved our ability to analyze and generate human language computationally. This article delves into advanced techniques for semantic analysis and generation, offering insights and practical examples for both beginners and seasoned practitioners in the domains of Data Science, Machine Learning, and NLP."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Advanceds",
      "item": "http://example.org/advanced/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "",
      "item": "http://example.org/advanced/Advanced_Natural_Language_Processing_Techniques_for_Semantic_Analysis_and_Generation/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "",
  "name": "",
  "description": "Advanced Natural Language Processing: Techniques for Semantic Analysis and Generation In the fast-evolving field of Natural Language Processing (NLP), understanding the nuances of language, its structure, and meaning has never been more important. Advancements in machine learning, data science, and artificial intelligence have significantly improved our ability to analyze and generate human language computationally. This article delves into advanced techniques for semantic analysis and generation, offering insights and practical examples for both beginners and seasoned practitioners in the domains of Data Science, Machine Learning, and NLP.",
  "keywords": [
    
  ],
  "articleBody": "Advanced Natural Language Processing: Techniques for Semantic Analysis and Generation In the fast-evolving field of Natural Language Processing (NLP), understanding the nuances of language, its structure, and meaning has never been more important. Advancements in machine learning, data science, and artificial intelligence have significantly improved our ability to analyze and generate human language computationally. This article delves into advanced techniques for semantic analysis and generation, offering insights and practical examples for both beginners and seasoned practitioners in the domains of Data Science, Machine Learning, and NLP.\nIntroduction Natural Language Processing stands at the intersection of computer science, artificial intelligence, and linguistics, aiming to bridge human communication and computational understanding. However, understanding the semantics - the meaning behind words and sentences - poses a complex challenge. Semantic analysis involves deciphering the context, intent, and nuances of language, while semantic generation focuses on creating meaningful, contextually relevant text. These processes are crucial for applications like chatbots, search engines, content summarization, and more.\nThis article explores advanced techniques for semantic analysis and generation, leveraging popular Python libraries like TensorFlow, Scikit-learn, and NLTK, among others. Through practical code snippets and explanations, we aim to provide actionable knowledge for enhancing your NLP projects.\nMain Body Semantic Analysis Word Embeddings with Word2Vec One fundamental technique in NLP is the use of word embeddings, which represent words in a high-dimensional space, capturing semantic relationships based on their context. Google’s Word2Vec is a popular method for creating word embeddings. Let’s see how we can generate word embeddings using the gensim library.\nfrom gensim.models import Word2Vec from gensim.utils import simple_preprocess # Sample text corpus corpus = [ \"Natural language processing enables computers to understand human language.\", \"Semantic analysis is a key part of natural language processing.\" ] # Preprocess the text and create a list of sentences tokenized_sentences = [simple_preprocess(sentence) for sentence in corpus] # Train a Word2Vec model model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4) # Retrieve the vector for a word vector = model.wv['language'] print(vector[:5]) # Output the first five elements of the vector for demonstration The output will be a 100-dimensional vector (the first five elements shown) representing the word “language” in the semantic space created by Word2Vec.\nSemantic Similarity with Cosine Similarity After obtaining word embeddings, we can measure semantic similarity between words or sentences by computing the cosine similarity between their vectors.\nfrom sklearn.metrics.pairwise import cosine_similarity # Assume vector1 and vector2 represent the vectors for two different words or sentences vector1 = model.wv['natural'] vector2 = model.wv['language'] # Compute cosine similarity similarity = cosine_similarity([vector1], [vector2]) print(similarity) This will output a similarity score ranging from -1 to 1, where 1 means identical.\nSemantic Generation Advancements in deep learning have enabled the development of models capable of generating human-like text. The Transformer architecture, introduced by Vaswani et al., has been particularly influential, leading to models like GPT (Generative Pre-trained Transformer).\nText Generation with GPT-2 Using the Hugging Face transformers library, we can easily leverage GPT-2 for text generation:\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer tokenizer = GPT2Tokenizer.from_pretrained('gpt2') model = GPT2LMHeadModel.from_pretrained('gpt2') # Encode some initial text inputs = tokenizer.encode(\"Natural language processing enables computers\", return_tensors='pt') # Generate text outputs = model.generate(inputs, max_length=50, num_return_sequences=1) print(tokenizer.decode(outputs[0], skip_special_tokens=True)) This code snippet initiates text generation from a given seed phrase, producing a continuation that mimics human language patterns.\nConclusion The field of NLP continues to advance, offering more sophisticated techniques for semantic analysis and generation. By understanding and leveraging these advanced methods, developers and researchers can build more intuitive, effective, and human-like applications. Through practical examples and explanations, we’ve explored some of the cutting-edge techniques in semantic analysis and generation. While this article provides a solid foundation, the rapidly evolving landscape of NLP ensures that there’s always more to learn and explore.\nAs we’ve seen, powerful libraries and models like Word2Vec, GPT-2, and the Transformer architecture provide the tools necessary for in-depth semantic analysis and generation. Whether you’re just beginning your journey in NLP or are looking to deepen your existing knowledge, these techniques offer a pathway to enhancing your applications and research. Continue experimenting, learning, and applying these advanced methods to unlock the full potential of Natural Language Processing.\n",
  "wordCount" : "686",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://example.org/advanced/Advanced_Natural_Language_Processing_Techniques_for_Semantic_Analysis_and_Generation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Driven Discovery - D3",
    "logo": {
      "@type": "ImageObject",
      "url": "http://example.org/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://example.org/" accesskey="h" title="Data Driven Discovery - D3 (Alt + H)">Data Driven Discovery - D3</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      
    </h1>
    <div class="post-meta">

</div>
  </header> 
  <div class="post-content"><h1 id="advanced-natural-language-processing-techniques-for-semantic-analysis-and-generation">Advanced Natural Language Processing: Techniques for Semantic Analysis and Generation<a hidden class="anchor" aria-hidden="true" href="#advanced-natural-language-processing-techniques-for-semantic-analysis-and-generation">#</a></h1>
<p>In the fast-evolving field of Natural Language Processing (NLP), understanding the nuances of language, its structure, and meaning has never been more important. Advancements in machine learning, data science, and artificial intelligence have significantly improved our ability to analyze and generate human language computationally. This article delves into advanced techniques for semantic analysis and generation, offering insights and practical examples for both beginners and seasoned practitioners in the domains of Data Science, Machine Learning, and NLP.</p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Natural Language Processing stands at the intersection of computer science, artificial intelligence, and linguistics, aiming to bridge human communication and computational understanding. However, understanding the semantics - the meaning behind words and sentences - poses a complex challenge. Semantic analysis involves deciphering the context, intent, and nuances of language, while semantic generation focuses on creating meaningful, contextually relevant text. These processes are crucial for applications like chatbots, search engines, content summarization, and more.</p>
<p>This article explores advanced techniques for semantic analysis and generation, leveraging popular Python libraries like TensorFlow, Scikit-learn, and NLTK, among others. Through practical code snippets and explanations, we aim to provide actionable knowledge for enhancing your NLP projects.</p>
<h2 id="main-body">Main Body<a hidden class="anchor" aria-hidden="true" href="#main-body">#</a></h2>
<h3 id="semantic-analysis">Semantic Analysis<a hidden class="anchor" aria-hidden="true" href="#semantic-analysis">#</a></h3>
<h4 id="word-embeddings-with-word2vec">Word Embeddings with Word2Vec<a hidden class="anchor" aria-hidden="true" href="#word-embeddings-with-word2vec">#</a></h4>
<p>One fundamental technique in NLP is the use of word embeddings, which represent words in a high-dimensional space, capturing semantic relationships based on their context. Google&rsquo;s Word2Vec is a popular method for creating word embeddings. Let&rsquo;s see how we can generate word embeddings using the gensim library.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> gensim.models <span style="color:#f92672">import</span> Word2Vec
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> gensim.utils <span style="color:#f92672">import</span> simple_preprocess
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Sample text corpus</span>
</span></span><span style="display:flex;"><span>corpus <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Natural language processing enables computers to understand human language.&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Semantic analysis is a key part of natural language processing.&#34;</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Preprocess the text and create a list of sentences</span>
</span></span><span style="display:flex;"><span>tokenized_sentences <span style="color:#f92672">=</span> [simple_preprocess(sentence) <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> corpus]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Train a Word2Vec model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> Word2Vec(sentences<span style="color:#f92672">=</span>tokenized_sentences, vector_size<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, window<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, min_count<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, workers<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Retrieve the vector for a word</span>
</span></span><span style="display:flex;"><span>vector <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>wv[<span style="color:#e6db74">&#39;language&#39;</span>]
</span></span><span style="display:flex;"><span>print(vector[:<span style="color:#ae81ff">5</span>])  <span style="color:#75715e"># Output the first five elements of the vector for demonstration</span>
</span></span></code></pre></div><p>The output will be a 100-dimensional vector (the first five elements shown) representing the word &ldquo;language&rdquo; in the semantic space created by Word2Vec.</p>
<h4 id="semantic-similarity-with-cosine-similarity">Semantic Similarity with Cosine Similarity<a hidden class="anchor" aria-hidden="true" href="#semantic-similarity-with-cosine-similarity">#</a></h4>
<p>After obtaining word embeddings, we can measure semantic similarity between words or sentences by computing the cosine similarity between their vectors.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics.pairwise <span style="color:#f92672">import</span> cosine_similarity
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Assume vector1 and vector2 represent the vectors for two different words or sentences</span>
</span></span><span style="display:flex;"><span>vector1 <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>wv[<span style="color:#e6db74">&#39;natural&#39;</span>]
</span></span><span style="display:flex;"><span>vector2 <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>wv[<span style="color:#e6db74">&#39;language&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Compute cosine similarity</span>
</span></span><span style="display:flex;"><span>similarity <span style="color:#f92672">=</span> cosine_similarity([vector1], [vector2])
</span></span><span style="display:flex;"><span>print(similarity)
</span></span></code></pre></div><p>This will output a similarity score ranging from -1 to 1, where 1 means identical.</p>
<h3 id="semantic-generation">Semantic Generation<a hidden class="anchor" aria-hidden="true" href="#semantic-generation">#</a></h3>
<p>Advancements in deep learning have enabled the development of models capable of generating human-like text. The Transformer architecture, introduced by Vaswani et al., has been particularly influential, leading to models like GPT (Generative Pre-trained Transformer).</p>
<h4 id="text-generation-with-gpt-2">Text Generation with GPT-2<a hidden class="anchor" aria-hidden="true" href="#text-generation-with-gpt-2">#</a></h4>
<p>Using the Hugging Face <code>transformers</code> library, we can easily leverage GPT-2 for text generation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> GPT2LMHeadModel, GPT2Tokenizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> GPT2Tokenizer<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#39;gpt2&#39;</span>)
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> GPT2LMHeadModel<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#39;gpt2&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Encode some initial text</span>
</span></span><span style="display:flex;"><span>inputs <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;Natural language processing enables computers&#34;</span>, return_tensors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;pt&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate text</span>
</span></span><span style="display:flex;"><span>outputs <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>generate(inputs, max_length<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, num_return_sequences<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>print(tokenizer<span style="color:#f92672">.</span>decode(outputs[<span style="color:#ae81ff">0</span>], skip_special_tokens<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>))
</span></span></code></pre></div><p>This code snippet initiates text generation from a given seed phrase, producing a continuation that mimics human language patterns.</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>The field of NLP continues to advance, offering more sophisticated techniques for semantic analysis and generation. By understanding and leveraging these advanced methods, developers and researchers can build more intuitive, effective, and human-like applications. Through practical examples and explanations, we&rsquo;ve explored some of the cutting-edge techniques in semantic analysis and generation. While this article provides a solid foundation, the rapidly evolving landscape of NLP ensures that there&rsquo;s always more to learn and explore.</p>
<p>As we&rsquo;ve seen, powerful libraries and models like Word2Vec, GPT-2, and the Transformer architecture provide the tools necessary for in-depth semantic analysis and generation. Whether you&rsquo;re just beginning your journey in NLP or are looking to deepen your existing knowledge, these techniques offer a pathway to enhancing your applications and research. Continue experimenting, learning, and applying these advanced methods to unlock the full potential of Natural Language Processing.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://example.org/">Data Driven Discovery - D3</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
