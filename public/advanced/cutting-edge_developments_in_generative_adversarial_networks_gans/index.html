<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cutting-Edge Developments in Generative Adversarial Networks (GANs) | Data Driven Discovery - D3</title>
<meta name="keywords" content="Deep Learning, Generative Adversarial Networks, Advanced Topic">
<meta name="description" content="Cutting-Edge Developments in Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) have taken the world of artificial intelligence and machine learning by storm. Their unique capability to generate new, synthetic instances of data that closely mimic real datasets is nothing short of revolutionary. From creating hyper-realistic images to generating new music, GANs are paving the way for incredible advancements in various fields. This article is designed to shed light on the latest, most cutting-edge developments in GAN technology.">
<meta name="author" content="">
<link rel="canonical" href="https://lustrous-paprenjak-b7c3d8.netlify.app/advanced/Cutting-Edge_Developments_in_Generative_Adversarial_Networks_GANs/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lustrous-paprenjak-b7c3d8.netlify.app/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/apple-touch-icon.png">
<link rel="mask-icon" href="https://lustrous-paprenjak-b7c3d8.netlify.app/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Cutting-Edge Developments in Generative Adversarial Networks (GANs)" />
<meta property="og:description" content="Cutting-Edge Developments in Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) have taken the world of artificial intelligence and machine learning by storm. Their unique capability to generate new, synthetic instances of data that closely mimic real datasets is nothing short of revolutionary. From creating hyper-realistic images to generating new music, GANs are paving the way for incredible advancements in various fields. This article is designed to shed light on the latest, most cutting-edge developments in GAN technology." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lustrous-paprenjak-b7c3d8.netlify.app/advanced/Cutting-Edge_Developments_in_Generative_Adversarial_Networks_GANs/" /><meta property="article:section" content="advanced" />
<meta property="article:published_time" content="2024-02-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-02-05T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Cutting-Edge Developments in Generative Adversarial Networks (GANs)"/>
<meta name="twitter:description" content="Cutting-Edge Developments in Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) have taken the world of artificial intelligence and machine learning by storm. Their unique capability to generate new, synthetic instances of data that closely mimic real datasets is nothing short of revolutionary. From creating hyper-realistic images to generating new music, GANs are paving the way for incredible advancements in various fields. This article is designed to shed light on the latest, most cutting-edge developments in GAN technology."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Advanceds",
      "item": "https://lustrous-paprenjak-b7c3d8.netlify.app/advanced/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Cutting-Edge Developments in Generative Adversarial Networks (GANs)",
      "item": "https://lustrous-paprenjak-b7c3d8.netlify.app/advanced/Cutting-Edge_Developments_in_Generative_Adversarial_Networks_GANs/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cutting-Edge Developments in Generative Adversarial Networks (GANs)",
  "name": "Cutting-Edge Developments in Generative Adversarial Networks (GANs)",
  "description": "Cutting-Edge Developments in Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) have taken the world of artificial intelligence and machine learning by storm. Their unique capability to generate new, synthetic instances of data that closely mimic real datasets is nothing short of revolutionary. From creating hyper-realistic images to generating new music, GANs are paving the way for incredible advancements in various fields. This article is designed to shed light on the latest, most cutting-edge developments in GAN technology.",
  "keywords": [
    "Deep Learning", "Generative Adversarial Networks", "Advanced Topic"
  ],
  "articleBody": "Cutting-Edge Developments in Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) have taken the world of artificial intelligence and machine learning by storm. Their unique capability to generate new, synthetic instances of data that closely mimic real datasets is nothing short of revolutionary. From creating hyper-realistic images to generating new music, GANs are paving the way for incredible advancements in various fields. This article is designed to shed light on the latest, most cutting-edge developments in GAN technology. We’ll delve deep into the topic, catering to both newcomers intrigued by the capabilities of GANs and seasoned professionals seeking the latest knowledge and techniques.\nIntroduction First introduced by Ian Goodfellow and his colleagues in 2014, GANs are a class of machine learning frameworks. They’re constructed from two neural networks: the generator, which creates data, and the discriminator, which evaluates it. Together, these networks undergo a form of adversarial training, akin to a forger trying to create a counterfeit painting and an art detective learning to detect the fake ones, refining their methods with each iteration.\nThe applications of GANs have been vast and varied, impacting fields such as art, medicine, and even video game content creation. As we move further into an era of artificial intelligence innovation, understanding and leveraging the power of GANs has become crucial.\nMain Body Let’s now dive into the contemporary advancements in GAN technology, analyzing how these developments are setting the stage for a future powered by synthetic data generation. We’ll also provide working code snippets implementing some GAN concepts, adhering to the Python programming language for clarity and accessibility.\nStyleGAN3: The Frontier of Realism One of the flagship developments in GANs has been NVIDIA’s StyleGAN series, culminating in StyleGAN3. StyleGAN3 addresses a critical challenge in GAN-generated imagery: generating consistent and realistic animations of faces. By improving the underlying architecture to maintain spatial coherence, StyleGAN3 has significantly reduced the distortions and artifacts typical of earlier iterations.\n# Note: Ensure you have TensorFlow and other necessary libraries installed before running this code. import tensorflow as tf # Placeholder snippet for loading a pre-trained StyleGAN3 model. # This is a conceptual example. Actual implementation would require downloading model weights. model = tf.keras.models.load_model('path_to_stylegan3_model') # Generate a sample image (without specific details due to complexity) noise = tf.random.normal([1, 512]) generated_image = model(noise) The real magic of StyleGAN3 lies in its detailed control over the synthesis process, enabling unprecedented customization of the generated images. However, the above code is only a simplified placeholder to illustrate the concept of loading and using a StyleGAN3 model. The actual usage would involve more complex preprocessing and model manipulation.\nGAN Inversion for Image Editing A fascinating area where GANs have shown promise is in image editing. GAN inversion refers to the process of taking a real image and finding the latent space representation that generates a similar image. This opens doors to high-quality image manipulation, such as altering facial features in portraits or adjusting lighting and textures in photographs.\n# Again, a simplified conceptual snippet. Actual implementation requires a trained GAN model. def invert_image_to_latent_space(model, image): # Conceptual function to find the latent space representation for image editing. pass # Conceptually inverting an image (placeholder function), # which then could be modified and fed back into the generator for editing. latent_representation = invert_image_to_latent_space(model, real_image) This method propels forward the capabilities in personalized content creation, fashion design preview, and even in the restoration of old photographs, offering a depth of customization previously unattainable.\nAdvanced Techniques in Training Stability One of the perennial challenges with GANs has been training stability. Newer algorithms and loss functions have emerged, aimed at mitigating these issues. For instance, the introduction of Wasserstein loss and the use of gradient penalty methods have significantly improved the stability of GAN training processes.\n# Implementing a basic Wasserstein loss function def wasserstein_loss(y_true, y_pred): return tf.reduce_mean(y_true * y_pred) # This is a simplified example. In practice, you'd apply this loss function in your GAN's training loop. Wasserstein loss provides a more meaningful gradient signal for the generator, avoiding common pitfalls like mode collapse. It represents the distance between the distribution of generated data and real data, offering a smoother training curve and better convergence properties.\nConclusion GANs continue to be at the forefront of innovation in machine learning, pushing the boundaries of what’s possible with artificial intelligence. From creating lifelike images to enhancing the realism of synthetic media, the potential applications are vast and far-reaching. The cutting-edge developments discussed, including StyleGAN3’s improvements, GAN inversion techniques, and advanced training methods, signify just the beginning of what’s achievable.\nUnderstanding and leveraging these advancements will be key for researchers, developers, and innovators looking to harness the power of GANs. As we continue to explore these technologies, we can anticipate a future enriched by highly realistic synthetic data, opening new avenues in content creation, scientific research, and beyond. Whether you’re just starting out or are deeply embedded in the field of AI, keeping abreast of these developments in GAN technology will undoubtedly be beneficial.\n",
  "wordCount" : "833",
  "inLanguage": "en",
  "datePublished": "2024-02-05T00:00:00Z",
  "dateModified": "2024-02-05T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lustrous-paprenjak-b7c3d8.netlify.app/advanced/Cutting-Edge_Developments_in_Generative_Adversarial_Networks_GANs/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Driven Discovery - D3",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lustrous-paprenjak-b7c3d8.netlify.app/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lustrous-paprenjak-b7c3d8.netlify.app/" accesskey="h" title="Data Driven Discovery - D3 (Alt + H)">Data Driven Discovery - D3</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Cutting-Edge Developments in Generative Adversarial Networks (GANs)
    </h1>
    <div class="post-meta"><span title='2024-02-05 00:00:00 +0000 UTC'>February 5, 2024</span>

</div>
  </header> 
  <div class="post-content"><h1 id="cutting-edge-developments-in-generative-adversarial-networks-gans">Cutting-Edge Developments in Generative Adversarial Networks (GANs)<a hidden class="anchor" aria-hidden="true" href="#cutting-edge-developments-in-generative-adversarial-networks-gans">#</a></h1>
<p>Generative Adversarial Networks (GANs) have taken the world of artificial intelligence and machine learning by storm. Their unique capability to generate new, synthetic instances of data that closely mimic real datasets is nothing short of revolutionary. From creating hyper-realistic images to generating new music, GANs are paving the way for incredible advancements in various fields. This article is designed to shed light on the latest, most cutting-edge developments in GAN technology. We&rsquo;ll delve deep into the topic, catering to both newcomers intrigued by the capabilities of GANs and seasoned professionals seeking the latest knowledge and techniques.</p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>First introduced by Ian Goodfellow and his colleagues in 2014, GANs are a class of machine learning frameworks. They&rsquo;re constructed from two neural networks: the generator, which creates data, and the discriminator, which evaluates it. Together, these networks undergo a form of adversarial training, akin to a forger trying to create a counterfeit painting and an art detective learning to detect the fake ones, refining their methods with each iteration.</p>
<p>The applications of GANs have been vast and varied, impacting fields such as art, medicine, and even video game content creation. As we move further into an era of artificial intelligence innovation, understanding and leveraging the power of GANs has become crucial.</p>
<h2 id="main-body">Main Body<a hidden class="anchor" aria-hidden="true" href="#main-body">#</a></h2>
<p>Let&rsquo;s now dive into the contemporary advancements in GAN technology, analyzing how these developments are setting the stage for a future powered by synthetic data generation. We&rsquo;ll also provide working code snippets implementing some GAN concepts, adhering to the Python programming language for clarity and accessibility.</p>
<h3 id="stylegan3-the-frontier-of-realism">StyleGAN3: The Frontier of Realism<a hidden class="anchor" aria-hidden="true" href="#stylegan3-the-frontier-of-realism">#</a></h3>
<p>One of the flagship developments in GANs has been NVIDIA&rsquo;s StyleGAN series, culminating in StyleGAN3. StyleGAN3 addresses a critical challenge in GAN-generated imagery: generating consistent and realistic animations of faces. By improving the underlying architecture to maintain spatial coherence, StyleGAN3 has significantly reduced the distortions and artifacts typical of earlier iterations.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Note: Ensure you have TensorFlow and other necessary libraries installed before running this code.</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> tensorflow <span style="color:#66d9ef">as</span> tf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Placeholder snippet for loading a pre-trained StyleGAN3 model.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This is a conceptual example. Actual implementation would require downloading model weights.</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>load_model(<span style="color:#e6db74">&#39;path_to_stylegan3_model&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate a sample image (without specific details due to complexity)</span>
</span></span><span style="display:flex;"><span>noise <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">512</span>])
</span></span><span style="display:flex;"><span>generated_image <span style="color:#f92672">=</span> model(noise)
</span></span></code></pre></div><p>The real magic of StyleGAN3 lies in its detailed control over the synthesis process, enabling unprecedented customization of the generated images. However, the above code is only a simplified placeholder to illustrate the concept of loading and using a StyleGAN3 model. The actual usage would involve more complex preprocessing and model manipulation.</p>
<h3 id="gan-inversion-for-image-editing">GAN Inversion for Image Editing<a hidden class="anchor" aria-hidden="true" href="#gan-inversion-for-image-editing">#</a></h3>
<p>A fascinating area where GANs have shown promise is in image editing. GAN inversion refers to the process of taking a real image and finding the latent space representation that generates a similar image. This opens doors to high-quality image manipulation, such as altering facial features in portraits or adjusting lighting and textures in photographs.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Again, a simplified conceptual snippet. Actual implementation requires a trained GAN model.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">invert_image_to_latent_space</span>(model, image):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Conceptual function to find the latent space representation for image editing.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Conceptually inverting an image (placeholder function),</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># which then could be modified and fed back into the generator for editing.</span>
</span></span><span style="display:flex;"><span>latent_representation <span style="color:#f92672">=</span> invert_image_to_latent_space(model, real_image)
</span></span></code></pre></div><p>This method propels forward the capabilities in personalized content creation, fashion design preview, and even in the restoration of old photographs, offering a depth of customization previously unattainable.</p>
<h3 id="advanced-techniques-in-training-stability">Advanced Techniques in Training Stability<a hidden class="anchor" aria-hidden="true" href="#advanced-techniques-in-training-stability">#</a></h3>
<p>One of the perennial challenges with GANs has been training stability. Newer algorithms and loss functions have emerged, aimed at mitigating these issues. For instance, the introduction of Wasserstein loss and the use of gradient penalty methods have significantly improved the stability of GAN training processes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Implementing a basic Wasserstein loss function</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">wasserstein_loss</span>(y_true, y_pred):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>reduce_mean(y_true <span style="color:#f92672">*</span> y_pred)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This is a simplified example. In practice, you&#39;d apply this loss function in your GAN&#39;s training loop.</span>
</span></span></code></pre></div><p>Wasserstein loss provides a more meaningful gradient signal for the generator, avoiding common pitfalls like mode collapse. It represents the distance between the distribution of generated data and real data, offering a smoother training curve and better convergence properties.</p>
<h3 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h3>
<p>GANs continue to be at the forefront of innovation in machine learning, pushing the boundaries of what&rsquo;s possible with artificial intelligence. From creating lifelike images to enhancing the realism of synthetic media, the potential applications are vast and far-reaching. The cutting-edge developments discussed, including StyleGAN3&rsquo;s improvements, GAN inversion techniques, and advanced training methods, signify just the beginning of what&rsquo;s achievable.</p>
<p>Understanding and leveraging these advancements will be key for researchers, developers, and innovators looking to harness the power of GANs. As we continue to explore these technologies, we can anticipate a future enriched by highly realistic synthetic data, opening new avenues in content creation, scientific research, and beyond. Whether you&rsquo;re just starting out or are deeply embedded in the field of AI, keeping abreast of these developments in GAN technology will undoubtedly be beneficial.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Deep-Learning/">Deep Learning</a></li>
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Generative-Adversarial-Networks/">Generative Adversarial Networks</a></li>
      <li><a href="https://lustrous-paprenjak-b7c3d8.netlify.app/tags/Advanced-Topic/">Advanced Topic</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://lustrous-paprenjak-b7c3d8.netlify.app/">Data Driven Discovery - D3</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
