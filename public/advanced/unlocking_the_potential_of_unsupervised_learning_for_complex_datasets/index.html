<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Data Driven Discovery - D3</title>
<meta name="keywords" content="">
<meta name="description" content="Unlocking the Potential of Unsupervised Learning for Complex Datasets In the vast universe of machine learning (ML), unsupervised learning stands out as a compelling avenue for model training where data isn&rsquo;t explicitly labeled. Unlike its supervised counterpart, unsupervised learning algorithms identify patterns, correlations, and structures from unlabeled data, opening diverse applications from customer segmentation to anomaly detection in complex datasets. This article aims to guide both beginners and advanced practitioners through the captivating world of unsupervised learning, focusing on methodologies, practical code snippets, and advanced tips to leverage unsupervised learning to its full potential.">
<meta name="author" content="">
<link rel="canonical" href="http://example.org/advanced/Unlocking_the_Potential_of_Unsupervised_Learning_for_Complex_Datasets/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://example.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://example.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://example.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://example.org/apple-touch-icon.png">
<link rel="mask-icon" href="http://example.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="" />
<meta property="og:description" content="Unlocking the Potential of Unsupervised Learning for Complex Datasets In the vast universe of machine learning (ML), unsupervised learning stands out as a compelling avenue for model training where data isn&rsquo;t explicitly labeled. Unlike its supervised counterpart, unsupervised learning algorithms identify patterns, correlations, and structures from unlabeled data, opening diverse applications from customer segmentation to anomaly detection in complex datasets. This article aims to guide both beginners and advanced practitioners through the captivating world of unsupervised learning, focusing on methodologies, practical code snippets, and advanced tips to leverage unsupervised learning to its full potential." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/advanced/Unlocking_the_Potential_of_Unsupervised_Learning_for_Complex_Datasets/" /><meta property="article:section" content="advanced" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="Unlocking the Potential of Unsupervised Learning for Complex Datasets In the vast universe of machine learning (ML), unsupervised learning stands out as a compelling avenue for model training where data isn&rsquo;t explicitly labeled. Unlike its supervised counterpart, unsupervised learning algorithms identify patterns, correlations, and structures from unlabeled data, opening diverse applications from customer segmentation to anomaly detection in complex datasets. This article aims to guide both beginners and advanced practitioners through the captivating world of unsupervised learning, focusing on methodologies, practical code snippets, and advanced tips to leverage unsupervised learning to its full potential."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Advanceds",
      "item": "http://example.org/advanced/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "",
      "item": "http://example.org/advanced/Unlocking_the_Potential_of_Unsupervised_Learning_for_Complex_Datasets/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "",
  "name": "",
  "description": "Unlocking the Potential of Unsupervised Learning for Complex Datasets In the vast universe of machine learning (ML), unsupervised learning stands out as a compelling avenue for model training where data isn\u0026rsquo;t explicitly labeled. Unlike its supervised counterpart, unsupervised learning algorithms identify patterns, correlations, and structures from unlabeled data, opening diverse applications from customer segmentation to anomaly detection in complex datasets. This article aims to guide both beginners and advanced practitioners through the captivating world of unsupervised learning, focusing on methodologies, practical code snippets, and advanced tips to leverage unsupervised learning to its full potential.",
  "keywords": [
    
  ],
  "articleBody": "Unlocking the Potential of Unsupervised Learning for Complex Datasets In the vast universe of machine learning (ML), unsupervised learning stands out as a compelling avenue for model training where data isn’t explicitly labeled. Unlike its supervised counterpart, unsupervised learning algorithms identify patterns, correlations, and structures from unlabeled data, opening diverse applications from customer segmentation to anomaly detection in complex datasets. This article aims to guide both beginners and advanced practitioners through the captivating world of unsupervised learning, focusing on methodologies, practical code snippets, and advanced tips to leverage unsupervised learning to its full potential.\nIntroduction to Unsupervised Learning Unsupervised learning is a class of machine learning techniques designed to infer patterns from unlabeled datasets. The absence of labels means the algorithm must make sense of the data without guidance, finding the underlying structure or distribution of the data itself. It’s like deciphering a puzzle without the picture on the box; challenging, yet rewarding. There are two main types:\nClustering: Groups similar data points together. Dimensionality Reduction: Reduces the number of variables under consideration. Unsupervised learning can handle complex datasets with intricate structures, making it invaluable in real-world applications where labeling data is impractical.\nDiving Into Clustering with K-Means Let’s start with a hands-on exploration of K-Means, a popular clustering algorithm. It partitions data into K distinct clusters based on their features.\nPrerequisite Installations Ensure you have the necessary libraries:\npip install scikit-learn matplotlib pandas The Code from sklearn.cluster import KMeans import matplotlib.pyplot as plt import numpy as np # Generating a sample dataset from sklearn.datasets import make_blobs X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0) # Applying K-Means kmeans = KMeans(n_clusters=4) kmeans.fit(X) y_kmeans = kmeans.predict(X) # Plotting the clusters plt.scatter(X[:,0], X[:,1], c=y_kmeans, cmap='viridis') centers = kmeans.cluster_centers_ plt.scatter(centers[:, 0], centers[:, 1], c='red', alpha=0.5) plt.show() The output plot reveals how the algorithm effectively groups the data points into four distinct clusters based on their similarity.\nUnveiling Hidden Structures with PCA Dimensionality Reduction, particularly Principal Component Analysis (PCA), is another unsupervised learning technique. It’s exceptionally beneficial when dealing with data characterized by a high number of dimensions.\nThe Code from sklearn.decomposition import PCA from sklearn.datasets import load_iris import matplotlib.pyplot as plt # Loading a sample dataset data = load_iris() X = data.data y = data.target # Applying PCA pca = PCA(n_components=2) X_r = pca.fit_transform(X) # Plotting the result targets = [0, 1, 2] colors = ['navy', 'turquoise', 'darkorange'] for target, color in zip(targets, colors): plt.scatter(X_r[y == target, 0], X_r[y == target, 1], color=color) plt.show() PCA reduces the dimensionality from four to two while preserving the essence of the dataset. This simplification makes it easier to visualize and understand complex datasets.\nAdvanced Tips Feature Scaling Prior to applying unsupervised learning algorithms, especially K-Means and PCA, feature scaling is crucial. It ensures that all features contribute equally to the result.\nChoosing the Number of Clusters Determining the optimal number of clusters in K-Means can be challenging. The Elbow Method is a practical approach to address this. It involves plotting the explained variance against the number of clusters and picking the elbow point as the optimal number.\nDomain Knowledge Incorporate domain knowledge wherever possible. Understanding the context can guide the interpretation of unsupervised learning outcomes, making them more actionable.\nConclusion Unsupervised learning offers a powerful toolkit for uncovering hidden structures in complex datasets, invaluable for exploratory data analysis, customer segmentation, anomaly detection, and beyond. While it presents challenges, such as the determination of the number of clusters or the reliance on feature scaling, its potential applications in real-world scenarios are immense. By mastering the techniques discussed and continuously experimenting, data scientists can unlock insights from data that would otherwise remain hidden. Unsupervised learning, with its ability to learn without explicit instructions, remains a fascinating field that promises to keep uncovering valuable information from the depths of untamed datasets.\nAs we venture further into the era of big data, the role of unsupervised learning will only grow, making it an essential skill for data professionals. Through careful application and continual learning, the potential of unsupervised learning to transform complex datasets into actionable insights is within reach.\n",
  "wordCount" : "678",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://example.org/advanced/Unlocking_the_Potential_of_Unsupervised_Learning_for_Complex_Datasets/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Driven Discovery - D3",
    "logo": {
      "@type": "ImageObject",
      "url": "http://example.org/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://example.org/" accesskey="h" title="Data Driven Discovery - D3 (Alt + H)">Data Driven Discovery - D3</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      
    </h1>
    <div class="post-meta">

</div>
  </header> 
  <div class="post-content"><h1 id="unlocking-the-potential-of-unsupervised-learning-for-complex-datasets">Unlocking the Potential of Unsupervised Learning for Complex Datasets<a hidden class="anchor" aria-hidden="true" href="#unlocking-the-potential-of-unsupervised-learning-for-complex-datasets">#</a></h1>
<p>In the vast universe of machine learning (ML), unsupervised learning stands out as a compelling avenue for model training where data isn&rsquo;t explicitly labeled. Unlike its supervised counterpart, unsupervised learning algorithms identify patterns, correlations, and structures from unlabeled data, opening diverse applications from customer segmentation to anomaly detection in complex datasets. This article aims to guide both beginners and advanced practitioners through the captivating world of unsupervised learning, focusing on methodologies, practical code snippets, and advanced tips to leverage unsupervised learning to its full potential.</p>
<h2 id="introduction-to-unsupervised-learning">Introduction to Unsupervised Learning<a hidden class="anchor" aria-hidden="true" href="#introduction-to-unsupervised-learning">#</a></h2>
<p>Unsupervised learning is a class of machine learning techniques designed to infer patterns from unlabeled datasets. The absence of labels means the algorithm must make sense of the data without guidance, finding the underlying structure or distribution of the data itself. It&rsquo;s like deciphering a puzzle without the picture on the box; challenging, yet rewarding. There are two main types:</p>
<ol>
<li><strong>Clustering</strong>: Groups similar data points together.</li>
<li><strong>Dimensionality Reduction</strong>: Reduces the number of variables under consideration.</li>
</ol>
<p>Unsupervised learning can handle complex datasets with intricate structures, making it invaluable in real-world applications where labeling data is impractical.</p>
<h2 id="diving-into-clustering-with-k-means">Diving Into Clustering with K-Means<a hidden class="anchor" aria-hidden="true" href="#diving-into-clustering-with-k-means">#</a></h2>
<p>Let&rsquo;s start with a hands-on exploration of <code>K-Means</code>, a popular clustering algorithm. It partitions data into K distinct clusters based on their features.</p>
<h3 id="prerequisite-installations">Prerequisite Installations<a hidden class="anchor" aria-hidden="true" href="#prerequisite-installations">#</a></h3>
<p>Ensure you have the necessary libraries:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install scikit-learn matplotlib pandas
</span></span></code></pre></div><h3 id="the-code">The Code<a hidden class="anchor" aria-hidden="true" href="#the-code">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.cluster <span style="color:#f92672">import</span> KMeans
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generating a sample dataset</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_blobs
</span></span><span style="display:flex;"><span>X, _ <span style="color:#f92672">=</span> make_blobs(n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>, centers<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, cluster_std<span style="color:#f92672">=</span><span style="color:#ae81ff">0.60</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Applying K-Means</span>
</span></span><span style="display:flex;"><span>kmeans <span style="color:#f92672">=</span> KMeans(n_clusters<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>kmeans<span style="color:#f92672">.</span>fit(X)
</span></span><span style="display:flex;"><span>y_kmeans <span style="color:#f92672">=</span> kmeans<span style="color:#f92672">.</span>predict(X)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plotting the clusters</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(X[:,<span style="color:#ae81ff">0</span>], X[:,<span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>y_kmeans, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;viridis&#39;</span>)
</span></span><span style="display:flex;"><span>centers <span style="color:#f92672">=</span> kmeans<span style="color:#f92672">.</span>cluster_centers_
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(centers[:, <span style="color:#ae81ff">0</span>], centers[:, <span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>The output plot reveals how the algorithm effectively groups the data points into four distinct clusters based on their similarity.</p>
<h2 id="unveiling-hidden-structures-with-pca">Unveiling Hidden Structures with PCA<a hidden class="anchor" aria-hidden="true" href="#unveiling-hidden-structures-with-pca">#</a></h2>
<p>Dimensionality Reduction, particularly Principal Component Analysis (PCA), is another unsupervised learning technique. It&rsquo;s exceptionally beneficial when dealing with data characterized by a high number of dimensions.</p>
<h3 id="the-code-1">The Code<a hidden class="anchor" aria-hidden="true" href="#the-code-1">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.decomposition <span style="color:#f92672">import</span> PCA
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> load_iris
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Loading a sample dataset</span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> load_iris()
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Applying PCA</span>
</span></span><span style="display:flex;"><span>pca <span style="color:#f92672">=</span> PCA(n_components<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>X_r <span style="color:#f92672">=</span> pca<span style="color:#f92672">.</span>fit_transform(X)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plotting the result</span>
</span></span><span style="display:flex;"><span>targets <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>]
</span></span><span style="display:flex;"><span>colors <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;navy&#39;</span>, <span style="color:#e6db74">&#39;turquoise&#39;</span>, <span style="color:#e6db74">&#39;darkorange&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> target, color <span style="color:#f92672">in</span> zip(targets, colors):
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>scatter(X_r[y <span style="color:#f92672">==</span> target, <span style="color:#ae81ff">0</span>], X_r[y <span style="color:#f92672">==</span> target, <span style="color:#ae81ff">1</span>], color<span style="color:#f92672">=</span>color)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>PCA reduces the dimensionality from four to two while preserving the essence of the dataset. This simplification makes it easier to visualize and understand complex datasets.</p>
<h2 id="advanced-tips">Advanced Tips<a hidden class="anchor" aria-hidden="true" href="#advanced-tips">#</a></h2>
<h3 id="feature-scaling">Feature Scaling<a hidden class="anchor" aria-hidden="true" href="#feature-scaling">#</a></h3>
<p>Prior to applying unsupervised learning algorithms, especially K-Means and PCA, feature scaling is crucial. It ensures that all features contribute equally to the result.</p>
<h3 id="choosing-the-number-of-clusters">Choosing the Number of Clusters<a hidden class="anchor" aria-hidden="true" href="#choosing-the-number-of-clusters">#</a></h3>
<p>Determining the optimal number of clusters in K-Means can be challenging. The Elbow Method is a practical approach to address this. It involves plotting the explained variance against the number of clusters and picking the elbow point as the optimal number.</p>
<h3 id="domain-knowledge">Domain Knowledge<a hidden class="anchor" aria-hidden="true" href="#domain-knowledge">#</a></h3>
<p>Incorporate domain knowledge wherever possible. Understanding the context can guide the interpretation of unsupervised learning outcomes, making them more actionable.</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>Unsupervised learning offers a powerful toolkit for uncovering hidden structures in complex datasets, invaluable for exploratory data analysis, customer segmentation, anomaly detection, and beyond. While it presents challenges, such as the determination of the number of clusters or the reliance on feature scaling, its potential applications in real-world scenarios are immense. By mastering the techniques discussed and continuously experimenting, data scientists can unlock insights from data that would otherwise remain hidden. Unsupervised learning, with its ability to learn without explicit instructions, remains a fascinating field that promises to keep uncovering valuable information from the depths of untamed datasets.</p>
<p>As we venture further into the era of big data, the role of unsupervised learning will only grow, making it an essential skill for data professionals. Through careful application and continual learning, the potential of unsupervised learning to transform complex datasets into actionable insights is within reach.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://example.org/">Data Driven Discovery - D3</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
