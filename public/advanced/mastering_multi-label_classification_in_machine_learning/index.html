<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Data Driven Discovery - D3</title>
<meta name="keywords" content="">
<meta name="description" content="Mastering Multi-Label Classification in Machine Learning Multi-label classification represents one of the more nuanced aspects of machine learning, straddling the complexities of understanding how to predict multiple labels for a single instance, rather than the traditional single label per instance. As the digital world grows exponentially, so does the demand for sophisticated models that can understand and predict multiple attributes, tags, or categories for a given piece of data. This article aims to shed light on multi-label classification, offering both beginners and advanced users actionable insights, complete with working code snippets that can be executed as-is.">
<meta name="author" content="">
<link rel="canonical" href="http://example.org/advanced/Mastering_Multi-Label_Classification_in_Machine_Learning/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://example.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://example.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://example.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://example.org/apple-touch-icon.png">
<link rel="mask-icon" href="http://example.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="" />
<meta property="og:description" content="Mastering Multi-Label Classification in Machine Learning Multi-label classification represents one of the more nuanced aspects of machine learning, straddling the complexities of understanding how to predict multiple labels for a single instance, rather than the traditional single label per instance. As the digital world grows exponentially, so does the demand for sophisticated models that can understand and predict multiple attributes, tags, or categories for a given piece of data. This article aims to shed light on multi-label classification, offering both beginners and advanced users actionable insights, complete with working code snippets that can be executed as-is." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/advanced/Mastering_Multi-Label_Classification_in_Machine_Learning/" /><meta property="article:section" content="advanced" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="Mastering Multi-Label Classification in Machine Learning Multi-label classification represents one of the more nuanced aspects of machine learning, straddling the complexities of understanding how to predict multiple labels for a single instance, rather than the traditional single label per instance. As the digital world grows exponentially, so does the demand for sophisticated models that can understand and predict multiple attributes, tags, or categories for a given piece of data. This article aims to shed light on multi-label classification, offering both beginners and advanced users actionable insights, complete with working code snippets that can be executed as-is."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Advanceds",
      "item": "http://example.org/advanced/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "",
      "item": "http://example.org/advanced/Mastering_Multi-Label_Classification_in_Machine_Learning/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "",
  "name": "",
  "description": "Mastering Multi-Label Classification in Machine Learning Multi-label classification represents one of the more nuanced aspects of machine learning, straddling the complexities of understanding how to predict multiple labels for a single instance, rather than the traditional single label per instance. As the digital world grows exponentially, so does the demand for sophisticated models that can understand and predict multiple attributes, tags, or categories for a given piece of data. This article aims to shed light on multi-label classification, offering both beginners and advanced users actionable insights, complete with working code snippets that can be executed as-is.",
  "keywords": [
    
  ],
  "articleBody": "Mastering Multi-Label Classification in Machine Learning Multi-label classification represents one of the more nuanced aspects of machine learning, straddling the complexities of understanding how to predict multiple labels for a single instance, rather than the traditional single label per instance. As the digital world grows exponentially, so does the demand for sophisticated models that can understand and predict multiple attributes, tags, or categories for a given piece of data. This article aims to shed light on multi-label classification, offering both beginners and advanced users actionable insights, complete with working code snippets that can be executed as-is.\nUnderstanding Multi-Label Classification At its core, multi-label classification involves predicting multiple outputs or tags for a single instance. Unlike multi-class classification, where each instance is mapped to a single label from a set of disjoint labels, multi-label classification allows for an instance to be associated with a set of labels, thereby embodying a richer understanding of the data.\nApplications of multi-label classification span a broad range, including image and video annotation, music categorization, text tagging for topics, and more. The complexity lies in the interconnectedness of the labels, which could be correlated, and thus, the prediction of one label might depend on others.\nApproaching the Multi-Label Classification Problem There are primarily two ways to approach a multi-label classification problem:\nProblem Transformation Methods: This approach transforms the multi-label problem into multiple single-label problems. Common strategies include:\nBinary Relevance: Treats each label as a separate single-class classification problem. Classifier Chains: Builds a chain of classifiers where each classifier deals with the label and adds it as a feature to the next classifier in the chain. Algorithm Adaptation Methods: This involves adapting algorithms to handle multi-label data directly. Some algorithms are inherently capable of multilabel classification, such as decision trees.\nDeep Dive into Multi-Label Classification with Python To grasp the practical aspects, let’s dive into an example of multi-label classification using a synthetic dataset. We’ll explore both a problem transformation method and an algorithm adaptation method using Python with popular libraries like scikit-learn.\nSetting Up the Environment First, ensure you have the necessary libraries installed:\npip install scikit-learn numpy Creating a Synthetic Dataset Let’s create a synthetic dataset suitable for multi-label classification:\nfrom sklearn.datasets import make_multilabel_classification import numpy as np # Create a synthetic multi-label dataset X, y = make_multilabel_classification(n_samples=1000, n_features=20, n_classes=5, n_labels=2, random_state=42) print(X.shape, y.shape) This code snippet creates a dataset with 1000 instances, each with 20 features and 5 possible labels, where each instance has 2 labels on average.\nBinary Relevance Approach We’ll use the binary relevance method as a starting point:\nfrom sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.multioutput import MultiOutputClassifier # Split the dataset X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) # Initialize the base classifier base_lr = LogisticRegression(solver='lbfgs') # Create the multi-output classifier multi_output_clf = MultiOutputClassifier(base_lr, n_jobs=-1) # Train the model multi_output_clf.fit(X_train, y_train) # Evaluate the model score = multi_output_clf.score(X_test, y_test) print(f\"Accuracy: {score}\") In this example, MultiOutputClassifier is used to wrap a LogisticRegression model, treating each label as a separate classification problem.\nAlgorithm Adaptation Approach Let’s look at using an algorithm that inherently supports multi-label classification:\nfrom sklearn.tree import DecisionTreeClassifier # Initialize the Decision Tree classifier dt_clf = DecisionTreeClassifier() # Train the model dt_clf.fit(X_train, y_train) # Evaluate the model score = dt_clf.score(X_test, y_test) print(f\"Accuracy: {score}\") Decision trees naturally handle multi-label classification by splitting nodes based on label combinations.\nConclusion Mastering multi-label classification requires understanding the nuances of dealing with multiple labels per instance and choosing the appropriate strategy based on the problem at hand. Through problem transformation and algorithm adaptation methods, machine learning practitioners can tackle these complex problems with greater confidence and precision. As with any machine learning endeavor, the choice of method and algorithm should be guided by the specific requirements and constraints of the task, as well as the nature of the data.\nWhereas this introduction and guide provide a starting point, the landscape of multi-label classification is rich and varied, offering many avenues for further exploration and optimization. Practitioners are encouraged to delve deeper into specialized methods and algorithms that can handle the intricacies of correlated labels and imbalanced datasets. Through experimentation and continuous learning, one can harness the full potential of multi-label classification to solve a myriad of real-world problems.\n",
  "wordCount" : "707",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://example.org/advanced/Mastering_Multi-Label_Classification_in_Machine_Learning/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Driven Discovery - D3",
    "logo": {
      "@type": "ImageObject",
      "url": "http://example.org/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://example.org/" accesskey="h" title="Data Driven Discovery - D3 (Alt + H)">Data Driven Discovery - D3</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      
    </h1>
    <div class="post-meta">

</div>
  </header> 
  <div class="post-content"><h1 id="mastering-multi-label-classification-in-machine-learning">Mastering Multi-Label Classification in Machine Learning<a hidden class="anchor" aria-hidden="true" href="#mastering-multi-label-classification-in-machine-learning">#</a></h1>
<p>Multi-label classification represents one of the more nuanced aspects of machine learning, straddling the complexities of understanding how to predict multiple labels for a single instance, rather than the traditional single label per instance. As the digital world grows exponentially, so does the demand for sophisticated models that can understand and predict multiple attributes, tags, or categories for a given piece of data. This article aims to shed light on multi-label classification, offering both beginners and advanced users actionable insights, complete with working code snippets that can be executed as-is.</p>
<h3 id="understanding-multi-label-classification">Understanding Multi-Label Classification<a hidden class="anchor" aria-hidden="true" href="#understanding-multi-label-classification">#</a></h3>
<p>At its core, multi-label classification involves predicting multiple outputs or tags for a single instance. Unlike multi-class classification, where each instance is mapped to a single label from a set of disjoint labels, multi-label classification allows for an instance to be associated with a set of labels, thereby embodying a richer understanding of the data.</p>
<p>Applications of multi-label classification span a broad range, including image and video annotation, music categorization, text tagging for topics, and more. The complexity lies in the interconnectedness of the labels, which could be correlated, and thus, the prediction of one label might depend on others.</p>
<h3 id="approaching-the-multi-label-classification-problem">Approaching the Multi-Label Classification Problem<a hidden class="anchor" aria-hidden="true" href="#approaching-the-multi-label-classification-problem">#</a></h3>
<p>There are primarily two ways to approach a multi-label classification problem:</p>
<ol>
<li>
<p><strong>Problem Transformation Methods</strong>: This approach transforms the multi-label problem into multiple single-label problems. Common strategies include:</p>
<ul>
<li><strong>Binary Relevance</strong>: Treats each label as a separate single-class classification problem.</li>
<li><strong>Classifier Chains</strong>: Builds a chain of classifiers where each classifier deals with the label and adds it as a feature to the next classifier in the chain.</li>
</ul>
</li>
<li>
<p><strong>Algorithm Adaptation Methods</strong>: This involves adapting algorithms to handle multi-label data directly. Some algorithms are inherently capable of multilabel classification, such as decision trees.</p>
</li>
</ol>
<h3 id="deep-dive-into-multi-label-classification-with-python">Deep Dive into Multi-Label Classification with Python<a hidden class="anchor" aria-hidden="true" href="#deep-dive-into-multi-label-classification-with-python">#</a></h3>
<p>To grasp the practical aspects, let&rsquo;s dive into an example of multi-label classification using a synthetic dataset. We&rsquo;ll explore both a problem transformation method and an algorithm adaptation method using Python with popular libraries like scikit-learn.</p>
<h4 id="setting-up-the-environment">Setting Up the Environment<a hidden class="anchor" aria-hidden="true" href="#setting-up-the-environment">#</a></h4>
<p>First, ensure you have the necessary libraries installed:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install scikit-learn numpy
</span></span></code></pre></div><h4 id="creating-a-synthetic-dataset">Creating a Synthetic Dataset<a hidden class="anchor" aria-hidden="true" href="#creating-a-synthetic-dataset">#</a></h4>
<p>Let&rsquo;s create a synthetic dataset suitable for multi-label classification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_multilabel_classification
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a synthetic multi-label dataset</span>
</span></span><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> make_multilabel_classification(n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>, n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>, n_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, n_labels<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(X<span style="color:#f92672">.</span>shape, y<span style="color:#f92672">.</span>shape)
</span></span></code></pre></div><p>This code snippet creates a dataset with 1000 instances, each with 20 features and 5 possible labels, where each instance has 2 labels on average.</p>
<h4 id="binary-relevance-approach">Binary Relevance Approach<a hidden class="anchor" aria-hidden="true" href="#binary-relevance-approach">#</a></h4>
<p>We&rsquo;ll use the binary relevance method as a starting point:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.multioutput <span style="color:#f92672">import</span> MultiOutputClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Split the dataset</span>
</span></span><span style="display:flex;"><span>X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the base classifier</span>
</span></span><span style="display:flex;"><span>base_lr <span style="color:#f92672">=</span> LogisticRegression(solver<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;lbfgs&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create the multi-output classifier</span>
</span></span><span style="display:flex;"><span>multi_output_clf <span style="color:#f92672">=</span> MultiOutputClassifier(base_lr, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Train the model</span>
</span></span><span style="display:flex;"><span>multi_output_clf<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Evaluate the model</span>
</span></span><span style="display:flex;"><span>score <span style="color:#f92672">=</span> multi_output_clf<span style="color:#f92672">.</span>score(X_test, y_test)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">{</span>score<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>In this example, <code>MultiOutputClassifier</code> is used to wrap a <code>LogisticRegression</code> model, treating each label as a separate classification problem.</p>
<h4 id="algorithm-adaptation-approach">Algorithm Adaptation Approach<a hidden class="anchor" aria-hidden="true" href="#algorithm-adaptation-approach">#</a></h4>
<p>Let&rsquo;s look at using an algorithm that inherently supports multi-label classification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.tree <span style="color:#f92672">import</span> DecisionTreeClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the Decision Tree classifier</span>
</span></span><span style="display:flex;"><span>dt_clf <span style="color:#f92672">=</span> DecisionTreeClassifier()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Train the model</span>
</span></span><span style="display:flex;"><span>dt_clf<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Evaluate the model</span>
</span></span><span style="display:flex;"><span>score <span style="color:#f92672">=</span> dt_clf<span style="color:#f92672">.</span>score(X_test, y_test)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">{</span>score<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Decision trees naturally handle multi-label classification by splitting nodes based on label combinations.</p>
<h3 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h3>
<p>Mastering multi-label classification requires understanding the nuances of dealing with multiple labels per instance and choosing the appropriate strategy based on the problem at hand. Through problem transformation and algorithm adaptation methods, machine learning practitioners can tackle these complex problems with greater confidence and precision. As with any machine learning endeavor, the choice of method and algorithm should be guided by the specific requirements and constraints of the task, as well as the nature of the data.</p>
<p>Whereas this introduction and guide provide a starting point, the landscape of multi-label classification is rich and varied, offering many avenues for further exploration and optimization. Practitioners are encouraged to delve deeper into specialized methods and algorithms that can handle the intricacies of correlated labels and imbalanced datasets. Through experimentation and continuous learning, one can harness the full potential of multi-label classification to solve a myriad of real-world problems.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://example.org/">Data Driven Discovery - D3</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
